{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3b71613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any, Dict, List\n",
    "from google import genai\n",
    "from google.genai.errors import APIError\n",
    "from dotenv import load_dotenv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b04147",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "\n",
    "# Verification\n",
    "print(os.getenv(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e594e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\n",
    "    \"wide_filled.csv\"\n",
    ")\n",
    "\n",
    "df = df_raw.copy()\n",
    "df[\"YEARWEEK\"] = df[\"YEARWEEK\"].astype(int)\n",
    "df = df.sort_values(\"YEARWEEK\")\n",
    "s = df['YEARWEEK'].astype(str)\n",
    "\n",
    "# Monday of each ISO year-week\n",
    "df['week_start'] = pd.to_datetime(s + '1', format='%G%V%u')\n",
    "train = df.iloc[0:468, 11].to_numpy()\n",
    "test = df.iloc[468:520, 11].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9725a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _serialize_series(arr, precision=2):\n",
    "    \"\"\"\n",
    "    Turn a numeric iterable into a comma-separated string.\n",
    "    - precision: exact number of digits after the decimal point\n",
    "    - NaN / missing -> empty token (i.e., consecutive commas)\n",
    "    - Example: _serialize_series([0.1, np.nan, 2], precision=4) -> '0.1000,,2.0000'\n",
    "    \"\"\"\n",
    "    a = np.asarray(arr, dtype=float)\n",
    "    toks = []\n",
    "    fmt = \"{:.\" + str(precision) + \"f}\"\n",
    "    for x in a:\n",
    "        if np.isnan(x):\n",
    "            toks.append(\"\")\n",
    "            continue\n",
    "        s = fmt.format(x)\n",
    "        # normalize negative zero like '-0.0000' -> '0.0000'\n",
    "        if float(s) == 0.0 and s.startswith('-'):\n",
    "            s = s[1:]\n",
    "        toks.append(s)\n",
    "    return \",\".join(toks)\n",
    "\n",
    "def _parse_numbers(text: str, expect_n: int) -> List[float]:\n",
    "    \"\"\"MOCK: Parses a comma-separated string into a list of floats,\n",
    "    handling empty tokens (e.g., \",,\").\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parts = text.strip().split(',')\n",
    "        if len(parts) != expect_n:\n",
    "            print(f\"Warning: Expected {expect_n} values, got {len(parts)} parts in: {text[:50]}...\")\n",
    "            # Attempt to fill with NaNs if necessary, or just process what we have\n",
    "            # For this context, we will try to parse up to expect_n elements.\n",
    "        \n",
    "        results = []\n",
    "        for part in parts[:expect_n]:\n",
    "            try:\n",
    "                # Replace empty string with NaN\n",
    "                results.append(float(part.strip()) if part.strip() else np.nan)\n",
    "            except ValueError:\n",
    "                # Handle non-numeric text if any slips through (shouldn't with good prompt)\n",
    "                results.append(np.nan)\n",
    "\n",
    "        # Pad with NaNs if fewer than expected elements were parsed\n",
    "        while len(results) < expect_n:\n",
    "             results.append(np.nan)\n",
    "             \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing text '{text[:50]}...': {e}\")\n",
    "        return [np.nan] * expect_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b6bf88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "def gemini_forecast(\n",
    "    train: List[float] | np.ndarray,\n",
    "    test: List[float] | np.ndarray,\n",
    "    model: str = \"gemini-2.5-flash\",\n",
    "    *,\n",
    "    n_samples: int = 1,\n",
    "    precision: int = 2,\n",
    "    max_tokens_per_step: int = 8,\n",
    "    prompt_level: int = 3,\n",
    "    api_key: str = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Forecast len(test) steps using the Google GenAI SDK (Gemini) with a SINGLE prompt string.\n",
    "\n",
    "    The functionality, input/output, and prompt structure are preserved.\n",
    "    \"\"\"\n",
    "    # 1. Initialize Gemini Client\n",
    "    try:\n",
    "        # The SDK automatically uses the GEMINI_API_KEY environment variable.\n",
    "        client = genai.Client(api_key=api_key or os.getenv(\"GEMINI_API_KEY\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Gemini Client: {e}\")\n",
    "        raise\n",
    "\n",
    "    train = np.asarray(train, dtype=float)\n",
    "    test  = np.asarray(test,  dtype=float)\n",
    "    steps = int(test.size)\n",
    "    \n",
    "    # Early exit for empty test set (result structure preserved)\n",
    "    if steps <= 0:\n",
    "        return {\n",
    "            \"preds_mean\": np.array([]),\n",
    "            \"rmse\": np.nan,\n",
    "            \"all_preds\": np.empty((0, 0)),\n",
    "            \"train\": train,\n",
    "            \"test\": test,\n",
    "            \"raw_texts\": [],\n",
    "            \"config\": {\n",
    "                \"model\": model,\n",
    "                \"n_samples\": int(n_samples),\n",
    "                \"precision\": int(precision),\n",
    "                \"max_tokens_per_step\": int(max_tokens_per_step),\n",
    "                \"prompt_level\": int(prompt_level),\n",
    "            },\n",
    "            \"meta\": {\"steps\": steps, \"prompt\": \"\"},\n",
    "        }\n",
    "\n",
    "    seq = _serialize_series(train, precision=precision)\n",
    "\n",
    "    # Clamp prompt_level to [1, 3]\n",
    "    level = max(1, min(3, int(prompt_level)))\n",
    "\n",
    "    # --- Build prompt in layers (identical to original) ---\n",
    "    parts = []\n",
    "\n",
    "    # Level 1: Task description\n",
    "    parts.append(\n",
    "        \"TASK DESCRIPTION:\\n\"\n",
    "        \"You are forecasting future values for a univariate time series.\\n\"\n",
    "        \"The goal is to predict future values given the historical data.\\n\"\n",
    "        \"***IMPORTANT: If the historical input sequence contains two consecutive commas (e.g., '1.23,,1.25'), the value between them is missing.***\\n\"\n",
    "    )\n",
    "\n",
    "    # Level 2: Data context (ILI)\n",
    "    if level >= 2:\n",
    "        parts.append(\n",
    "            \"\\nDATA CONTEXT:\\n\"\n",
    "            \"- The sequence represents *weekly Percentage of Visits for Influenza-Like Illness (ILI).* \\n\"\n",
    "            \"- Each value is the percent of all healthcare visits attributed to ILI in a given week.\\n\"\n",
    "            \"- The historical sequence you see includes data up to around September 2024.\\n\"\n",
    "        )\n",
    "\n",
    "    # Level 3: Modeling guidance\n",
    "    if level >= 3:\n",
    "        parts.append(\n",
    "            \"\\nMODELING GUIDANCE:\\n\"\n",
    "            \"- When forecasting, explicitly consider:\\n\"\n",
    "            \"  • Long-term trend (overall increase, decrease, or stability over multiple seasons).\\n\"\n",
    "            \"  • Seasonality (typical winter influenza peaks and off-season lows each year).\\n\"\n",
    "            \"  • Randomness and noise (week-to-week fluctuations and irregular spikes).\\n\"\n",
    "            \"- Use these components implicitly in your reasoning when extending the series.\\n\"\n",
    "        )\n",
    "\n",
    "    # Output rules (always included)\n",
    "    max_output_tokens = steps * max_tokens_per_step\n",
    "    parts.append(\n",
    "        \"\\nOUTPUT RULES:\\n\"\n",
    "        \" - Output ONLY the next values as a comma-separated list.\\n\"\n",
    "        \" - No spaces, no text, no explanations.\\n\\n\"\n",
    "        f\"INPUT SEQUENCE (comma-separated):\\n{seq}\\n\\n\"\n",
    "        f\"TASK: Predict the next {steps} weekly ILI percentage values.\\n\"\n",
    "        f\"OUTPUT FORMAT EXAMPLE (for 3 steps): 1.23,1.25,1.27\\n\"\n",
    "        \"Remember: Output ONLY the comma-separated numbers.\"\n",
    "    )\n",
    "\n",
    "    prompt = \"\".join(parts)\n",
    "\n",
    "    samples = max(1, int(n_samples))\n",
    "    raw_texts, preds_list = [], []\n",
    "\n",
    "    # 2. Call Gemini API for each sample\n",
    "    for _ in range(samples):\n",
    "        raw = \"\"\n",
    "        try:\n",
    "            # Use generate_content for text generation.\n",
    "            response = client.models.generate_content(\n",
    "                model=model,\n",
    "                contents=prompt\n",
    "            )\n",
    "            raw = response.text.strip()\n",
    "            \n",
    "        except APIError as e:\n",
    "            raw = f\"API_ERROR: {e}\"\n",
    "            print(f\"Gemini API Error: {e}\")\n",
    "        except Exception as e:\n",
    "            raw = f\"GENERIC_ERROR: {e}\"\n",
    "            print(f\"Generic Error: {e}\")\n",
    "            \n",
    "        raw_texts.append(raw)\n",
    "        \n",
    "        # 3. Parse and store predictions\n",
    "        preds_list.append(np.asarray(_parse_numbers(raw, steps), dtype=float))\n",
    "\n",
    "    # 4. Calculate final metrics\n",
    "    all_preds = np.stack(preds_list, axis=0)                  # (n_samples, steps)\n",
    "    preds_mean = np.nanmean(all_preds, axis=0) # Use nanmean to handle NaNs from parsing errors\n",
    "    \n",
    "    # Calculate RMSE, handling potential NaNs in the prediction mean\n",
    "    if np.any(np.isnan(preds_mean)):\n",
    "        valid_indices = ~np.isnan(preds_mean)\n",
    "        if np.any(valid_indices):\n",
    "            rmse = float(np.sqrt(np.mean((preds_mean[valid_indices] - test[valid_indices]) ** 2)))\n",
    "        else:\n",
    "            rmse = np.nan\n",
    "    else:\n",
    "        rmse = float(np.sqrt(np.mean((preds_mean - test) ** 2))) # RMSE vs true test\n",
    "\n",
    "    # 5. Return the result dictionary\n",
    "    return {\n",
    "        \"preds_mean\": preds_mean,\n",
    "        \"rmse\": rmse,\n",
    "        \"all_preds\": all_preds,\n",
    "        \"train\": train,\n",
    "        \"test\": test,\n",
    "        \"raw_texts\": raw_texts,\n",
    "        \"config\": {\n",
    "            \"model\": model,\n",
    "            \"n_samples\": samples,\n",
    "            \"precision\": int(precision),\n",
    "            \"max_tokens_per_step\": int(max_tokens_per_step),\n",
    "            \"prompt_level\": level,\n",
    "        },\n",
    "        \"meta\": {\n",
    "            \"steps\": steps,\n",
    "            \"prompt\": prompt,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c394637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_forecast_plot(\n",
    "    res,\n",
    "    time_points,\n",
    "    title=\"Gemini Forecast (train, test truth, and prediction)\",\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"Value\",\n",
    "    ax=None,\n",
    "    legend_loc=\"best\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot GPT forecast results (no train predictions or CIs).\n",
    "    Expects `res` from gpt_forecast_llmtime(...) that contains:\n",
    "        - res[\"train\"]      : 1D array of train values\n",
    "        - res[\"test\"]       : 1D array of test values (truth)\n",
    "        - res[\"preds_mean\"] : 1D array of predictions for test horizon\n",
    "\n",
    "    Args:\n",
    "        res         : dict from gpt_forecast_llmtime (or similarly shaped)\n",
    "        time_points : 1D array-like of length len(train) + len(test)\n",
    "        title/xlabel/ylabel : plot labels\n",
    "        ax          : optional matplotlib Axes\n",
    "        legend_loc  : legend location\n",
    "\n",
    "    Returns:\n",
    "        (fig, ax)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    train = np.asarray(res[\"train\"], dtype=float)\n",
    "    test  = np.asarray(res[\"test\"], dtype=float)\n",
    "    y_pred_test = np.asarray(res[\"preds_mean\"], dtype=float)\n",
    "\n",
    "    n_train = train.shape[0]\n",
    "    n_test  = test.shape[0]\n",
    "    if y_pred_test.shape[0] != n_test:\n",
    "        raise ValueError(f\"preds_mean length ({y_pred_test.shape[0]}) must equal test length ({n_test}).\")\n",
    "\n",
    "    # Coerce time_points to 1D numpy array, accept pandas Index/Series if present\n",
    "    try:\n",
    "        import pandas as pd  # optional\n",
    "        if isinstance(time_points, (pd.Series, pd.Index)):\n",
    "            x = np.asarray(time_points.to_numpy()).ravel()\n",
    "        else:\n",
    "            x = np.asarray(time_points).ravel()\n",
    "    except Exception:\n",
    "        x = np.asarray(time_points).ravel()\n",
    "\n",
    "    if x.shape[0] != n_train + n_test:\n",
    "        raise ValueError(f\"`time_points` must have length {n_train + n_test} (got {x.shape[0]}).\")\n",
    "\n",
    "    x_train = x[:n_train]\n",
    "    x_test  = x[n_train:]\n",
    "\n",
    "    created_fig = False\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        created_fig = True\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "\n",
    "    # Plot true series\n",
    "    ax.plot(x_train, train, label=\"Train (true)\")\n",
    "    ax.plot(x_test,  test,  label=\"Test (true)\")\n",
    "\n",
    "    # Plot GPT predictions on test horizon\n",
    "    ax.plot(x_test, y_pred_test, \"--\", label=\"Test (Gemini prediction)\")\n",
    "\n",
    "    # Vertical separator at train/test boundary (draw at last train time if exists)\n",
    "    if n_train > 0:\n",
    "        ax.axvline(x_train[-1], linestyle=\":\", alpha=0.6)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.legend(loc=legend_loc)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb63301",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[260:468, 11].to_numpy()\n",
    "test = df.iloc[468:520, 11].to_numpy()\n",
    "\n",
    "all_res = []\n",
    "for i in range(50):\n",
    "    time.sleep(10)\n",
    "    res = gemini_forecast(train=train, test=test)\n",
    "    all_res.append(res)\n",
    "\n",
    "import pickle\n",
    "with open(\"all_res.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a64366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = gemini_forecast(train, test, model = \"gemini-2.5-flash\", prompt_level = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c56b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_seed = 12345\n",
    "df_half = df.copy()\n",
    "df_half = df_half.iloc[len(df_half) // 2 :].reset_index(drop=True)\n",
    "\n",
    "n_train = 208\n",
    "missing_rates = np.round(np.arange(0.0, 0.61, 0.2), 2)   # 0.0 ... 0.8\n",
    "\n",
    "prompt_level = 3\n",
    "\n",
    "region_cols = [c for c in df_half.columns if c not in [\"YEARWEEK\", \"week_start\"]]\n",
    "# region_cols = region_cols[:2].copy()\n",
    "# Make sure it's truly a DataFrame (not Series), with explicit index/columns names\n",
    "results_5_missing = pd.DataFrame(\n",
    "    index=pd.Index(missing_rates, name=\"missing_rate\"),\n",
    "    columns=pd.Index(region_cols, name=\"region\"),\n",
    "    dtype=object\n",
    ")\n",
    "\n",
    "for region_idx, region in enumerate(region_cols):\n",
    "    y = df_half[region].to_numpy(dtype=float)\n",
    "    train_full = y[:n_train].copy()\n",
    "    test_full  = y[n_train:].copy()\n",
    "    assert np.isfinite(train_full).all(), f\"Train has NaNs for region {region}.\"\n",
    "\n",
    "    for r_idx, rate in enumerate(missing_rates):\n",
    "        rng = np.random.default_rng(base_seed + region_idx * 10_000 + r_idx)\n",
    "\n",
    "        train_masked = train_full.copy()\n",
    "        k = int(round(rate * len(train_masked)))\n",
    "        if k > 0:\n",
    "            drop_idx = rng.choice(len(train_masked), size=k, replace=False)\n",
    "            train_masked[drop_idx] = np.nan\n",
    "            # ensure at least 2 observed remain\n",
    "            obs_count = int(np.isfinite(train_masked).sum())\n",
    "            if obs_count < 2:\n",
    "                to_restore = rng.choice(drop_idx, size=(2 - obs_count), replace=False)\n",
    "                train_masked[to_restore] = train_full[to_restore]\n",
    "\n",
    "        res = gemini_forecast(\n",
    "            train=train_masked,\n",
    "            test=test_full,\n",
    "            prompt_level = prompt_level\n",
    "        )\n",
    "\n",
    "        time.sleep(10)\n",
    "\n",
    "        # POSitional assignment avoids the \"Incompatible indexer with Series\" issue\n",
    "        results_5_missing.iat[r_idx, region_idx] = res\n",
    "\n",
    "    print(region)\n",
    "\n",
    "output_filename = f\"results_p{prompt_level}_missing.pkl.gz\"\n",
    "results_5_missing.to_pickle(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "401c3def",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = gemini_forecast(\n",
    "            train=train_masked,\n",
    "            test=test_full,\n",
    "            prompt_level = 3\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52058b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_5_missing.iat[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = gemini_forecast_plot(\n",
    "    results_5_missing.iat[3, 8],\n",
    "    time_points=df_half[\"week_start\"],      # length = n_train + n_test\n",
    "    xlabel=\"Week\",\n",
    "    ylabel=\"Value\",\n",
    "\ttitle=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1e15db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rmse_boxplots(results_df: pd.DataFrame, title: str = 'Distribution of Model RMSE by Missing Rate'):\n",
    "    \"\"\"\n",
    "    Generates side-by-side box plots for the RMSE distribution across different \n",
    "    missing rate rows in the input DataFrame.\n",
    "\n",
    "    The function iterates through each row (missing rate), extracts the 'rmse'\n",
    "    from the structured object in each cell, ignores NaN values, and plots the\n",
    "    resulting distribution.\n",
    "\n",
    "    Args:\n",
    "        results_df: The DataFrame (e.g., results_5_missing) where rows are missing rates,\n",
    "                    columns are regions, and cells contain result objects (e.g., {'rmse': 0.5}).\n",
    "        title: The title for the generated plot.\n",
    "    \"\"\"\n",
    "    # 1. Apply the extraction function to all cells\n",
    "    rmse_data = results_df.applymap(extract_rmse)\n",
    "\n",
    "    # 2. Prepare data for plotting\n",
    "    data_to_plot = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate over the rows (missing rates)\n",
    "    for rate, series in rmse_data.iterrows():\n",
    "        # Drop NaN values (where forecasts failed) and convert to a list\n",
    "        clean_data = series.dropna().tolist()\n",
    "        \n",
    "        # Ensure there is data to plot for this rate\n",
    "        if clean_data:\n",
    "            data_to_plot.append(clean_data)\n",
    "            # Format the label nicely (e.g., 0.2 -> 20%)\n",
    "            labels.append(f\"{rate * 100:.0f}% Missing\")\n",
    "\n",
    "    if not data_to_plot:\n",
    "        print(\"Error: No valid RMSE data was extracted for plotting.\")\n",
    "        return\n",
    "\n",
    "    # 3. Generate the box plots\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Define colors for better visualization\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(data_to_plot)))\n",
    "    \n",
    "    bp = plt.boxplot(data_to_plot, \n",
    "                     patch_artist=True, \n",
    "                     labels=labels,\n",
    "                     medianprops={'color': 'black'},\n",
    "                     flierprops={'marker': 'o', 'markersize': 5, 'markerfacecolor': 'red', 'alpha': 0.6})\n",
    "\n",
    "    # Color the boxes\n",
    "    for box, color in zip(bp['boxes'], colors):\n",
    "        box.set_facecolor(color)\n",
    "        box.set_alpha(0.7)\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(results_df.index.name.replace('_', ' ').title() if results_df.index.name else 'Grouping Variable', fontsize=12)\n",
    "    plt.ylabel('Root Mean Square Error (RMSE) Distribution', fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def extract_rmse(result_object: Any) -> float:\n",
    "    \"\"\"\n",
    "    Safely extracts the RMSE value from a single forecast result object.\n",
    "\n",
    "    Args:\n",
    "        result_object: The content of a single cell in the results_5_missing DataFrame.\n",
    "                       Expected to be a dictionary, or None/NaN if the forecast failed.\n",
    "\n",
    "    Returns:\n",
    "        The extracted RMSE value as a float, or np.nan if extraction fails.\n",
    "    \"\"\"\n",
    "    if result_object is None or pd.isna(result_object):\n",
    "        return np.nan\n",
    "    try:\n",
    "        # Assumes the structure is a dictionary with a key named 'rmse'\n",
    "        rmse_value = result_object.get('rmse')\n",
    "        # Ensure the value itself is a valid number before returning\n",
    "        if isinstance(rmse_value, (int, float)) and not np.isnan(rmse_value):\n",
    "            return float(rmse_value)\n",
    "        return np.nan\n",
    "    except AttributeError:\n",
    "        # Handles cases where result_object is not a dictionary\n",
    "        return np.nan\n",
    "    except Exception:\n",
    "        # Catch any other unexpected errors during extraction\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34505cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rmse_boxplots(results_5_missing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (irts)",
   "language": "python",
   "name": "irts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
